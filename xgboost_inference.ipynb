{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"xgboost_inference.ipynb\"  # Manually set the notebook name\n",
    "\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# from pathlib import Path\n",
    "# import os\n",
    "# from typing import Callable\n",
    "\n",
    "# import polars as pl\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "# import optuna\n",
    "# from optuna_integration.wandb import WeightsAndBiasesCallback\n",
    "# from optuna_integration.xgboost import XGBoostPruningCallback\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# from sklearn.compose import TransformedTargetRegressor\n",
    "# import shap\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.express as px\n",
    "\n",
    "# import wandb\n",
    "# from wandb.integration.xgboost import WandbCallback\n",
    "# from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose training run from which to load the model, etc.\n",
    "train_run_name = 'helpful-flower-65'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:lfaq82w2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf99335140640a6b13feebb174e1a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.877 MB of 0.880 MB uploaded (0.018 MB deduped)\\r'), FloatProgress(value=0.996657â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 2.1%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dry-brook-66</strong> at: <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/lfaq82w2' target=\"_blank\">https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/lfaq82w2</a><br/> View project at: <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge' target=\"_blank\">https://wandb.ai/esedx12/traffic-forecasting-challenge</a><br/>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240908_212006-lfaq82w2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:lfaq82w2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/emil/Desktop/Beam-Level Traffic Forecasting Challenge/wandb/run-20240908_212110-gp99vxeu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/gp99vxeu' target=\"_blank\">morning-cloud-67</a></strong> to <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge' target=\"_blank\">https://wandb.ai/esedx12/traffic-forecasting-challenge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/gp99vxeu' target=\"_blank\">https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/gp99vxeu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:13:45.244177, resuming normal operation.\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"traffic-forecasting-challenge\", tags=[train_run_name], job_type='inference', entity=\"esedx12\", config=config, save_code=True, mode=('dryrun' if DEBUG else 'online'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "checkpoints_dir = 'checkpoints'\n",
    "xgboost_models_dir = Path(checkpoints_dir) / train_run_name\n",
    "\n",
    "models = {}\n",
    "for file_name in os.listdir(xgboost_models_dir):\n",
    "    if file_name.endswith('.ubj'):\n",
    "        model_name = file_name[:-4]\n",
    "        model_path = xgboost_models_dir / file_name\n",
    "        models[model_name] = xgb.Booster(model_file=str(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "data_dir = Path('input-data')\n",
    "thp_vol = pl.read_csv(data_dir / 'traffic_DLThpVol.csv')  # This is the target variable\n",
    "prb = pl.read_csv(data_dir / 'traffic_DLPRB.csv')\n",
    "thp_time = pl.read_csv(data_dir / 'traffic_DLThpTime.csv')\n",
    "mr_number = pl.read_csv(data_dir / 'traffic_MR_number.csv')\n",
    "\n",
    "target_dataframes = {\n",
    "    'thp_vol': thp_vol,\n",
    "    'prb': prb,\n",
    "    'thp_time': thp_time,\n",
    "    'mr_number': mr_number\n",
    "}\n",
    "\n",
    "# Rename first col to 'hour'\n",
    "for k, v in target_dataframes.items():\n",
    "    target_dataframes[k] = v.rename({'': \"idx_hour\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Step Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_step(target_dataframes: dict[pl.DataFrame], model: xgb.Booster, config: wandb.Config) -> dict[pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Predict one step into the future using a trained model.\n",
    "    Takes DataFrames of len n, returns DataFrames of len n + 1.\n",
    "    \"\"\"\n",
    "    template_df = next(iter(target_dataframes.values()))\n",
    "    predict_hour = template_df['idx_hour'][-1] + 1\n",
    "\n",
    "    null_row = pl.DataFrame({col: [None] if not col == 'idx_hour' else predict_hour for col in template_df.columns})\n",
    "    target_dataframes = {k: pl.concat([v, null_row], how='vertical_relaxed') for k, v in target_dataframes.items()}\n",
    "\n",
    "    target_names = list(target_dataframes.keys())\n",
    "    feature_dfs = create_all_feature_dfs(target_dataframes, config)\n",
    "    feature_dfs = {k: v.tail(1) for k, v in feature_dfs.items()}  # maybe turn in to lazyframe for efficiency?\n",
    "    X_predict = convert_to_long_format(feature_dfs)\n",
    "    idx_hour, beam_id = X_predict['idx_hour'], X_predict['beam_id']\n",
    "    X_predict = X_predict.drop(dropped_cols)\n",
    "\n",
    "    # We predict only the idx immediately folling the last idx in the input, ie a single row\n",
    "    y_predicted_long = model.predict(X_predict)\n",
    "    y_predicted_long = pl.DataFrame(y_predicted_long, schema=target_names).with_columns([idx_hour, beam_id])\n",
    "    y_predicted_wide = convert_to_wide_format(y_predicted_long, output_df_names=target_names)\n",
    "\n",
    "    return {target_name: pl.concat([target_dataframes[target_name].head(-1), y_predicted_wide[target_name]], how='vertical_relaxed') for target_name in target_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multi_step(target_dataframes: dict[pl.DataFrame], model: xgb.Booster, config: wandb.Config, num_steps: int, max_lag=None) -> dict[pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Predict multiple steps into the future using a trained model.\n",
    "    Takes DataFrames of len n, returns DataFrames of len n + num_steps.\n",
    "    \"\"\"\n",
    "    if max_lag:\n",
    "        target_dataframes = {k: v.tail(max_lag + 5) for k, v in target_dataframes.items()}\n",
    "\n",
    "    for _ in tqdm(range(num_steps)):\n",
    "        target_dataframes = predict_one_step(target_dataframes, model, config)\n",
    "\n",
    "    return target_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_train_df = create_long_train_df(target_dataframes, wandb.config)\n",
    "long_test_df = create_long_train_df(test_dataframes, wandb.config)\n",
    "\n",
    "dropped_cols = ['idx_hour', 'beam_id']\n",
    "target_cols = list(target_dataframes.keys())\n",
    "\n",
    "X_train, y_train = long_train_df.drop(dropped_cols + target_cols), long_train_df.select(target_cols)\n",
    "X_test, y_test = long_test_df.drop(dropped_cols + target_cols), long_test_df.select(target_cols)\n",
    "\n",
    "wandb.log({'train shape': X_train.shape, 'test shape': X_test.shape, 'train_feats': X_train.columns,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbcbd78b09543d08602950335628303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2432706/3820107680.py:19: DeprecationWarning:\n",
      "\n",
      "The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'mean_horizontal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_multi_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtail\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataframes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_dataframes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthp_vol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_horizontal\u001b[49m()\n",
      "\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'mean_horizontal'"
     ]
    }
   ],
   "source": [
    "y = predict_multi_step({k: v.tail(80) for k, v in train_dataframes.items()}, model, wandb.config, num_steps=len(test_dataframes['thp_vol'])).mean_horizontal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(Y_true: pl.DataFrame, Y_pred: pl.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Compute the mean absolute error between two DataFrames.\n",
    "    \"\"\"\n",
    "    assert (Y_true['idx_hour'] == Y_pred['idx_hour']).all(), \"DataFrames must be aligned\"\n",
    "\n",
    "    return (Y_true.drop('idx_hour') - Y_pred.drop('idx_hour')).select(pl.all().abs().mean()).mean_horizontal()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24911949991279875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_absolute_error(test_dataframes['thp_vol'], y['thp_vol'].tail(len(test_dataframes['thp_vol'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...on Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...on Validation and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission CSV\n",
    "\n",
    "* Hours in 5 weeks: 840\n",
    "* Hours in 6 weeks: 1008\n",
    "* We need period 841-1008 (841-1009 with Python list indexing)\n",
    "\n",
    "* Hours in 10 weeks: 1680\n",
    "* Hours in 11 weeks: 1848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_half_submission_df(input_df: pl.DataFrame, weeks: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a submission CSV file from a Polars DataFrame.\n",
    "    \"\"\"\n",
    "    if weeks == '5w-6w':\n",
    "        range = [841, 1008]\n",
    "    elif weeks == '10w-11w':\n",
    "        range = [1681, 1848]\n",
    "\n",
    "    # Choose rows with first column 'idx_hour' having the values 671-840.\n",
    "    input_df = input_df.filter(pl.col('idx_hour').is_in(range)).with_row_index()\n",
    "\n",
    "    # Check that shape of dataframe is (168, 2881)\n",
    "    assert input_df.shape == (168, 2881), f\"Expected shape (168, 2881), got {input_df.shape}\"\n",
    "\n",
    "    # Check that there is no null value in the dataframe\n",
    "    assert input_df.is_null().any().any() == False, \"Submission dataframe contains null values\"\n",
    "\n",
    "    # Stack the dataframe with f'traffic_DLThpVol_test_5w-6w_{hour}_{beam_id}' as index\n",
    "    # where it cycles through the values 671-840 for hour and then the beam_ids, which are colnames of input_df\n",
    "    return input_df.unpivot(index='idx_hour').with_columns(\n",
    "        (pl.struct(pl.all()).map_elements(lambda row: f'traffic_DLThpVol_test_5w-6w_{row['row_index']}_{row[\"variable\"]}', return_dtype=pl.String)).alias('ID')\n",
    "    ).select(['ID', 'value']).rename({'value': 'Target'})\n",
    "\n",
    "\n",
    "def create_submission_csv(input_df: pl.DataFrame, output_filename='traffic_forecast.csv', archiving_dir='submission-csvs-archive') -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a submission CSV file from data in input format that's been extended to cover weeks 5-6 and 10-11.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create half submission dataframes\n",
    "    half_submission_5w_6w = create_half_submission_df(input_df, '5w-6w')\n",
    "    half_submission_10w_11w = create_half_submission_df(input_df, '10w-11w')\n",
    "\n",
    "    # Concatenate the two half submission dataframes\n",
    "    submission_df = pl.concat([half_submission_5w_6w, half_submission_10w_11w], how='vertical')\n",
    "\n",
    "    # Save the submission dataframe to a CSV file for submission\n",
    "    submission_df.write_csv(output_filename)\n",
    "    \n",
    "    # Save the submission dataframe to a CSV file for archiving\n",
    "    if archiving_dir:\n",
    "        archiving_dir = Path(archiving_dir)\n",
    "        archiving_dir.mkdir(parents=True, exist_ok=True)\n",
    "        submission_df.write_csv(archiving_dir / f'{wandb.run.name}_{output_filename}')\n",
    "\n",
    "    return submission_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
