{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"xgboost_inference.ipynb\"  # Manually set the notebook name\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "DEBUG = False\n",
    "# Load the inference config from the YAML file\n",
    "\n",
    "with open('configs/direct_inference_config_11_10_24.yaml', 'r') as f:\n",
    "    train_config = yaml.safe_load(f)\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "train_config = dotdict(train_config)\n",
    "\n",
    "inference_config = {\n",
    "    'prediction_length': 168,\n",
    "    'create_submission_csv': True\n",
    "}\n",
    "\n",
    "# Update the checkpoints directory to 'checkpoints_final'\n",
    "checkpoints_dir = 'checkpoints_final'\n",
    "xgboost_models_dir = Path(checkpoints_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8400ec555c704aa0ba9c8567b13567eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load all models\n",
    "models = {}\n",
    "for file_name in tqdm(os.listdir(xgboost_models_dir)):\n",
    "    if file_name.startswith('forward_shift_'):\n",
    "        shift = int(file_name.split('_')[-1])\n",
    "        model_path = xgboost_models_dir / file_name\n",
    "        with open(model_path, 'rb') as f:\n",
    "            models[shift] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Read the CSV files\n",
    "data_dir = Path('input-data')\n",
    "target_dataframes = {\n",
    "    'thp_vol': pl.read_csv(data_dir / 'traffic_DLThpVol.csv'),  # This is the target variable\n",
    "    'prb': pl.read_csv(data_dir / 'traffic_DLPRB.csv'),\n",
    "    'thp_time': pl.read_csv(data_dir / 'traffic_DLThpTime.csv'),\n",
    "    'mr_number': pl.read_csv(data_dir / 'traffic_MR_number.csv')\n",
    "}\n",
    "\n",
    "idx_hour_series = target_dataframes['thp_vol']['']\n",
    "\n",
    "for k, v in target_dataframes.items():\n",
    "    target_dataframes[k] = v.drop('')\n",
    "\n",
    "template_df = target_dataframes['thp_vol']\n",
    "\n",
    "predict_hour = 840\n",
    "\n",
    "null_row = pl.DataFrame({beam_id: [None] for beam_id in template_df.columns})\n",
    "\n",
    "target_dataframes = {k: pl.concat([v, null_row], how='vertical_relaxed') for k, v in target_dataframes.items()}\n",
    "\n",
    "target_names = list(target_dataframes.keys())\n",
    "feature_dfs = utils.create_all_feature_dfs(target_dataframes, idx_hour_series, train_config)\n",
    "feature_dfs = {k: v.tail(1) for k, v in feature_dfs.items()}  # maybe turn in to lazyframe for efficiency?\n",
    "X_predict = utils.convert_to_long_format(feature_dfs)\n",
    "\n",
    "cat_types = utils.make_id_cat_type(template_df.columns)\n",
    "X_predict = X_predict.to_pandas()\n",
    "for col in ['beam_id', 'cell_id', 'station_id']:\n",
    "    if col in X_predict.columns:\n",
    "        X_predict[col] = X_predict[col].astype(cat_types[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d506acf9e1d4d7cac083951b2be6527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "ys_predicted_wide = []\n",
    "\n",
    "for shift in tqdm(range(168)):\n",
    "    y_predicted = models[shift].predict(X_predict)\n",
    "\n",
    "    idx_hour = pl.DataFrame({'idx_hour': [840 + shift] * len(template_df.columns)})\n",
    "\n",
    "    y_predicted_long_df = pl.DataFrame({'idx_hour': idx_hour, 'beam_id': X_predict['beam_id'], 'thp_vol': y_predicted})\n",
    "\n",
    "    y_predicted_wide = utils.convert_to_wide_format(y_predicted_long_df, ['thp_vol'])['thp_vol']\n",
    "\n",
    "    ys_predicted_wide.append(y_predicted_wide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "predictions_wide = pl.concat(ys_predicted_wide, how='vertical')\n",
    "predictions_wide = predictions_wide.with_columns(idx_hour=pl.Series(range(840, 1008)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (168, 2_881)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>idx_hour</th><th>0_0_0</th><th>0_0_1</th><th>0_0_2</th><th>0_0_3</th><th>0_0_4</th><th>0_0_5</th><th>0_0_6</th><th>0_0_7</th><th>0_0_8</th><th>0_0_9</th><th>0_0_10</th><th>0_0_11</th><th>0_0_12</th><th>0_0_13</th><th>0_0_14</th><th>0_0_15</th><th>0_0_16</th><th>0_0_17</th><th>0_0_18</th><th>0_0_19</th><th>0_0_20</th><th>0_0_21</th><th>0_0_22</th><th>0_0_23</th><th>0_0_24</th><th>0_0_25</th><th>0_0_26</th><th>0_0_27</th><th>0_0_28</th><th>0_0_29</th><th>0_0_30</th><th>0_0_31</th><th>0_1_0</th><th>0_1_1</th><th>0_1_2</th><th>0_1_3</th><th>&hellip;</th><th>29_1_27</th><th>29_1_28</th><th>29_1_29</th><th>29_1_30</th><th>29_1_31</th><th>29_2_0</th><th>29_2_1</th><th>29_2_2</th><th>29_2_3</th><th>29_2_4</th><th>29_2_5</th><th>29_2_6</th><th>29_2_7</th><th>29_2_8</th><th>29_2_9</th><th>29_2_10</th><th>29_2_11</th><th>29_2_12</th><th>29_2_13</th><th>29_2_14</th><th>29_2_15</th><th>29_2_16</th><th>29_2_17</th><th>29_2_18</th><th>29_2_19</th><th>29_2_20</th><th>29_2_21</th><th>29_2_22</th><th>29_2_23</th><th>29_2_24</th><th>29_2_25</th><th>29_2_26</th><th>29_2_27</th><th>29_2_28</th><th>29_2_29</th><th>29_2_30</th><th>29_2_31</th></tr><tr><td>i64</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>840</td><td>0.461486</td><td>0.103442</td><td>0.14711</td><td>0.068884</td><td>1.105122</td><td>0.475052</td><td>0.09189</td><td>0.068884</td><td>0.588862</td><td>0.610352</td><td>0.117408</td><td>0.137233</td><td>0.644805</td><td>0.139171</td><td>0.134169</td><td>0.105918</td><td>0.097251</td><td>0.275353</td><td>1.339129</td><td>0.705991</td><td>0.123535</td><td>0.107277</td><td>0.127729</td><td>0.339758</td><td>0.085048</td><td>0.098066</td><td>1.37333</td><td>0.082317</td><td>0.095719</td><td>0.158356</td><td>0.09264</td><td>0.07508</td><td>0.072502</td><td>0.171782</td><td>0.140857</td><td>0.502418</td><td>&hellip;</td><td>0.378553</td><td>0.570243</td><td>0.877174</td><td>0.252508</td><td>0.069086</td><td>0.091609</td><td>0.102281</td><td>0.097378</td><td>0.0768</td><td>0.070058</td><td>0.096816</td><td>0.161302</td><td>0.098579</td><td>0.080093</td><td>0.212345</td><td>0.096378</td><td>0.095538</td><td>0.096449</td><td>0.292107</td><td>0.102383</td><td>0.099029</td><td>0.069389</td><td>0.104655</td><td>0.096977</td><td>0.278365</td><td>0.173926</td><td>0.082786</td><td>0.124096</td><td>0.068713</td><td>0.093333</td><td>0.081932</td><td>0.080994</td><td>0.080556</td><td>0.068901</td><td>0.088005</td><td>0.099411</td><td>0.074781</td></tr><tr><td>841</td><td>0.346771</td><td>0.104956</td><td>0.3642</td><td>0.070777</td><td>0.725037</td><td>0.47322</td><td>0.086983</td><td>0.070777</td><td>0.525958</td><td>0.395227</td><td>0.122652</td><td>0.127459</td><td>0.393492</td><td>0.152312</td><td>0.123007</td><td>0.122495</td><td>0.095271</td><td>0.176803</td><td>1.163849</td><td>0.480911</td><td>0.137013</td><td>0.138097</td><td>0.13346</td><td>0.324713</td><td>0.085406</td><td>0.093995</td><td>0.154344</td><td>0.084067</td><td>0.09403</td><td>0.149887</td><td>0.086003</td><td>0.074696</td><td>0.072087</td><td>0.180052</td><td>0.129335</td><td>0.467746</td><td>&hellip;</td><td>0.27385</td><td>0.66014</td><td>0.548925</td><td>0.193116</td><td>0.069083</td><td>0.091681</td><td>0.119051</td><td>0.099459</td><td>0.078562</td><td>0.072588</td><td>0.096002</td><td>0.183678</td><td>0.097856</td><td>0.076908</td><td>0.190425</td><td>0.114711</td><td>0.099412</td><td>0.105025</td><td>0.202014</td><td>0.111289</td><td>0.095364</td><td>0.070277</td><td>0.092499</td><td>0.096794</td><td>0.199281</td><td>0.100288</td><td>0.078952</td><td>0.121183</td><td>0.071347</td><td>0.086277</td><td>0.078001</td><td>0.0795</td><td>0.079036</td><td>0.069812</td><td>0.088021</td><td>0.095875</td><td>0.074376</td></tr><tr><td>842</td><td>0.312044</td><td>0.137974</td><td>0.956416</td><td>0.070082</td><td>0.533667</td><td>0.491734</td><td>0.083906</td><td>0.070082</td><td>0.367781</td><td>0.0518</td><td>0.128116</td><td>0.131564</td><td>0.28491</td><td>0.214477</td><td>0.14256</td><td>0.162862</td><td>0.105578</td><td>0.219768</td><td>1.123015</td><td>0.393527</td><td>0.192512</td><td>0.199407</td><td>0.182047</td><td>0.277616</td><td>0.079466</td><td>0.097078</td><td>0.141454</td><td>0.077482</td><td>0.095992</td><td>0.162511</td><td>0.076884</td><td>0.070996</td><td>0.071204</td><td>0.180175</td><td>0.123239</td><td>0.270621</td><td>&hellip;</td><td>0.264366</td><td>0.47229</td><td>0.395678</td><td>0.154001</td><td>0.068517</td><td>0.091223</td><td>0.134313</td><td>0.103212</td><td>0.074296</td><td>0.07309</td><td>0.096937</td><td>0.271062</td><td>0.105211</td><td>0.077193</td><td>0.229091</td><td>0.178292</td><td>0.1085</td><td>0.124598</td><td>0.183993</td><td>0.125484</td><td>0.099165</td><td>0.070735</td><td>0.091383</td><td>0.101167</td><td>0.165055</td><td>0.08274</td><td>0.078235</td><td>0.09871</td><td>0.071433</td><td>0.08509</td><td>0.079603</td><td>0.077342</td><td>0.077517</td><td>0.068456</td><td>0.085651</td><td>0.096756</td><td>0.085613</td></tr><tr><td>843</td><td>0.256408</td><td>0.146319</td><td>0.144487</td><td>0.071674</td><td>0.641792</td><td>0.366624</td><td>0.084175</td><td>0.071674</td><td>0.281305</td><td>0.178115</td><td>0.141256</td><td>0.119906</td><td>0.260864</td><td>0.187928</td><td>0.134269</td><td>0.139499</td><td>0.103823</td><td>0.214634</td><td>0.932818</td><td>0.226384</td><td>0.168473</td><td>0.177292</td><td>0.172015</td><td>0.25701</td><td>0.081144</td><td>0.096496</td><td>0.100195</td><td>0.088367</td><td>0.092697</td><td>0.14328</td><td>0.079478</td><td>0.072043</td><td>0.071444</td><td>0.167093</td><td>0.108961</td><td>0.208146</td><td>&hellip;</td><td>0.24916</td><td>0.440034</td><td>0.30887</td><td>0.134441</td><td>0.070195</td><td>0.089118</td><td>0.129243</td><td>0.10086</td><td>0.075407</td><td>0.07452</td><td>0.101216</td><td>0.228939</td><td>0.105606</td><td>0.078254</td><td>0.204459</td><td>0.1571</td><td>0.111729</td><td>0.121196</td><td>0.158519</td><td>0.121469</td><td>0.100946</td><td>0.071303</td><td>0.089933</td><td>0.103331</td><td>0.156645</td><td>0.077789</td><td>0.07881</td><td>0.089243</td><td>0.072275</td><td>0.086618</td><td>0.08156</td><td>0.080355</td><td>0.077835</td><td>0.06953</td><td>0.085817</td><td>0.098264</td><td>0.07589</td></tr><tr><td>844</td><td>0.201087</td><td>0.143179</td><td>0.16632</td><td>0.07232</td><td>0.517022</td><td>0.354426</td><td>0.084704</td><td>0.072635</td><td>0.195417</td><td>0.151439</td><td>0.13693</td><td>0.122025</td><td>0.180761</td><td>0.186344</td><td>0.151403</td><td>0.158687</td><td>0.113019</td><td>0.181516</td><td>0.702928</td><td>0.206651</td><td>0.149926</td><td>0.175239</td><td>0.162114</td><td>0.222103</td><td>0.082036</td><td>0.093864</td><td>0.087678</td><td>0.081165</td><td>0.090841</td><td>0.125476</td><td>0.081493</td><td>0.072635</td><td>0.072332</td><td>0.136798</td><td>0.100723</td><td>0.228552</td><td>&hellip;</td><td>0.209984</td><td>0.405753</td><td>0.247368</td><td>0.122692</td><td>0.071858</td><td>0.086731</td><td>0.13388</td><td>0.098436</td><td>0.075976</td><td>0.075591</td><td>0.096837</td><td>0.215622</td><td>0.106575</td><td>0.080185</td><td>0.18451</td><td>0.140212</td><td>0.108815</td><td>0.120908</td><td>0.123515</td><td>0.118473</td><td>0.100682</td><td>0.071501</td><td>0.093696</td><td>0.106902</td><td>0.145347</td><td>0.079269</td><td>0.080939</td><td>0.086445</td><td>0.072798</td><td>0.088355</td><td>0.082125</td><td>0.082773</td><td>0.079596</td><td>0.070511</td><td>0.085437</td><td>0.09678</td><td>0.078004</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1003</td><td>0.76124</td><td>0.186156</td><td>0.868758</td><td>0.077338</td><td>3.338638</td><td>2.455235</td><td>0.095133</td><td>0.077338</td><td>0.739765</td><td>0.924496</td><td>0.234689</td><td>0.315722</td><td>0.961915</td><td>0.436202</td><td>0.316979</td><td>0.276733</td><td>0.155126</td><td>0.967403</td><td>1.288057</td><td>0.638234</td><td>0.516168</td><td>0.512105</td><td>0.798533</td><td>0.434205</td><td>0.100423</td><td>0.134692</td><td>0.155371</td><td>0.084654</td><td>0.129919</td><td>0.240834</td><td>0.094344</td><td>0.077338</td><td>0.079789</td><td>0.444324</td><td>0.174854</td><td>0.216443</td><td>&hellip;</td><td>0.575744</td><td>0.993154</td><td>0.668</td><td>0.212426</td><td>0.080438</td><td>0.111839</td><td>0.33327</td><td>0.249925</td><td>0.078342</td><td>0.077338</td><td>0.140178</td><td>0.592295</td><td>0.181254</td><td>0.08195</td><td>1.018844</td><td>0.552964</td><td>0.168125</td><td>0.257193</td><td>0.284096</td><td>0.272058</td><td>0.160295</td><td>0.077338</td><td>0.097255</td><td>0.167579</td><td>0.437013</td><td>0.104835</td><td>0.088466</td><td>0.121484</td><td>0.077338</td><td>0.097871</td><td>0.107458</td><td>0.103457</td><td>0.080433</td><td>0.076884</td><td>0.101394</td><td>0.141376</td><td>0.08195</td></tr><tr><td>1004</td><td>0.857234</td><td>0.184682</td><td>0.27787</td><td>0.07595</td><td>4.142357</td><td>3.002193</td><td>0.097703</td><td>0.07595</td><td>0.565626</td><td>0.885516</td><td>0.256127</td><td>0.326732</td><td>1.119742</td><td>0.458974</td><td>0.249441</td><td>0.23578</td><td>0.15534</td><td>0.846855</td><td>1.435119</td><td>0.710054</td><td>0.431074</td><td>0.447414</td><td>0.503308</td><td>0.405256</td><td>0.101315</td><td>0.138648</td><td>0.250338</td><td>0.084282</td><td>0.129307</td><td>0.23338</td><td>0.093366</td><td>0.07595</td><td>0.078154</td><td>0.620921</td><td>0.159009</td><td>0.228297</td><td>&hellip;</td><td>0.533916</td><td>0.980322</td><td>0.673203</td><td>0.213137</td><td>0.0796</td><td>0.112935</td><td>0.285759</td><td>0.24829</td><td>0.079411</td><td>0.076208</td><td>0.144215</td><td>0.466695</td><td>0.175344</td><td>0.079996</td><td>0.652474</td><td>0.377499</td><td>0.172627</td><td>0.210092</td><td>0.329396</td><td>0.253477</td><td>0.153918</td><td>0.076399</td><td>0.098592</td><td>0.156716</td><td>0.370271</td><td>0.120622</td><td>0.085288</td><td>0.126401</td><td>0.07595</td><td>0.098599</td><td>0.105133</td><td>0.101386</td><td>0.079043</td><td>0.07595</td><td>0.103158</td><td>0.159747</td><td>0.082998</td></tr><tr><td>1005</td><td>0.782135</td><td>0.164116</td><td>0.351139</td><td>0.077257</td><td>3.645724</td><td>2.321768</td><td>0.102878</td><td>0.077257</td><td>0.415691</td><td>0.460047</td><td>0.335542</td><td>0.297672</td><td>1.164669</td><td>0.321998</td><td>0.189505</td><td>0.183533</td><td>0.146818</td><td>0.639726</td><td>1.890159</td><td>0.747457</td><td>0.293731</td><td>0.326523</td><td>0.378659</td><td>0.496702</td><td>0.095171</td><td>0.131344</td><td>0.237333</td><td>0.086816</td><td>0.129963</td><td>0.212502</td><td>0.08694</td><td>0.077257</td><td>0.080505</td><td>0.57791</td><td>0.150834</td><td>0.242493</td><td>&hellip;</td><td>0.449237</td><td>0.955954</td><td>0.661402</td><td>0.245135</td><td>0.083624</td><td>0.115748</td><td>0.192033</td><td>0.175267</td><td>0.083035</td><td>0.077257</td><td>0.140233</td><td>0.257763</td><td>0.153205</td><td>0.081804</td><td>0.412722</td><td>0.205211</td><td>0.140483</td><td>0.170843</td><td>0.405438</td><td>0.212397</td><td>0.133734</td><td>0.07771</td><td>0.102768</td><td>0.137082</td><td>0.320988</td><td>0.142064</td><td>0.089403</td><td>0.144772</td><td>0.077257</td><td>0.102138</td><td>0.100164</td><td>0.092733</td><td>0.082816</td><td>0.077257</td><td>0.107566</td><td>0.14758</td><td>0.085454</td></tr><tr><td>1006</td><td>0.649139</td><td>0.155732</td><td>0.353077</td><td>0.077999</td><td>2.857275</td><td>1.250584</td><td>0.103841</td><td>0.077999</td><td>0.437379</td><td>0.459047</td><td>0.27269</td><td>0.273132</td><td>0.796274</td><td>0.280279</td><td>0.174086</td><td>0.227004</td><td>0.131093</td><td>0.493074</td><td>1.579648</td><td>0.708604</td><td>0.226275</td><td>0.220429</td><td>0.242419</td><td>0.393824</td><td>0.093722</td><td>0.124845</td><td>0.189097</td><td>0.092527</td><td>0.129286</td><td>0.178563</td><td>0.089495</td><td>0.077999</td><td>0.081121</td><td>0.476042</td><td>0.165003</td><td>0.268883</td><td>&hellip;</td><td>0.41227</td><td>0.870932</td><td>0.757358</td><td>0.262681</td><td>0.082125</td><td>0.108814</td><td>0.172276</td><td>0.149076</td><td>0.085403</td><td>0.081242</td><td>0.137327</td><td>0.244356</td><td>0.139213</td><td>0.082191</td><td>0.345578</td><td>0.167103</td><td>0.13662</td><td>0.156557</td><td>0.309279</td><td>0.190712</td><td>0.131305</td><td>0.077999</td><td>0.097296</td><td>0.135758</td><td>0.267968</td><td>0.159091</td><td>0.085848</td><td>0.151604</td><td>0.077999</td><td>0.108381</td><td>0.095178</td><td>0.093831</td><td>0.084707</td><td>0.077999</td><td>0.111247</td><td>0.168184</td><td>0.085715</td></tr><tr><td>1007</td><td>0.480786</td><td>0.154954</td><td>0.316957</td><td>0.077433</td><td>2.415637</td><td>0.993645</td><td>0.108978</td><td>0.077433</td><td>0.570047</td><td>0.795416</td><td>0.253516</td><td>0.230061</td><td>0.55052</td><td>0.247504</td><td>0.173963</td><td>0.210997</td><td>0.128247</td><td>0.481703</td><td>2.442377</td><td>0.87718</td><td>0.194061</td><td>0.190535</td><td>0.203939</td><td>0.423368</td><td>0.098051</td><td>0.124316</td><td>0.463229</td><td>0.088516</td><td>0.126256</td><td>0.175815</td><td>0.090223</td><td>0.08028</td><td>0.079469</td><td>0.348699</td><td>0.161086</td><td>0.323153</td><td>&hellip;</td><td>0.374728</td><td>0.586673</td><td>0.750772</td><td>0.277635</td><td>0.079798</td><td>0.108374</td><td>0.152822</td><td>0.133897</td><td>0.083743</td><td>0.084243</td><td>0.131887</td><td>0.246101</td><td>0.127387</td><td>0.083801</td><td>0.252961</td><td>0.170084</td><td>0.128247</td><td>0.142107</td><td>0.312114</td><td>0.179234</td><td>0.127769</td><td>0.078232</td><td>0.107351</td><td>0.128686</td><td>0.265017</td><td>0.162086</td><td>0.084207</td><td>0.154414</td><td>0.077433</td><td>0.105172</td><td>0.093958</td><td>0.089939</td><td>0.083347</td><td>0.077433</td><td>0.106205</td><td>0.172368</td><td>0.08104</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (168, 2_881)\n",
       "┌──────────┬──────────┬──────────┬──────────┬───┬──────────┬──────────┬──────────┬──────────┐\n",
       "│ idx_hour ┆ 0_0_0    ┆ 0_0_1    ┆ 0_0_2    ┆ … ┆ 29_2_28  ┆ 29_2_29  ┆ 29_2_30  ┆ 29_2_31  │\n",
       "│ ---      ┆ ---      ┆ ---      ┆ ---      ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ i64      ┆ f32      ┆ f32      ┆ f32      ┆   ┆ f32      ┆ f32      ┆ f32      ┆ f32      │\n",
       "╞══════════╪══════════╪══════════╪══════════╪═══╪══════════╪══════════╪══════════╪══════════╡\n",
       "│ 840      ┆ 0.461486 ┆ 0.103442 ┆ 0.14711  ┆ … ┆ 0.068901 ┆ 0.088005 ┆ 0.099411 ┆ 0.074781 │\n",
       "│ 841      ┆ 0.346771 ┆ 0.104956 ┆ 0.3642   ┆ … ┆ 0.069812 ┆ 0.088021 ┆ 0.095875 ┆ 0.074376 │\n",
       "│ 842      ┆ 0.312044 ┆ 0.137974 ┆ 0.956416 ┆ … ┆ 0.068456 ┆ 0.085651 ┆ 0.096756 ┆ 0.085613 │\n",
       "│ 843      ┆ 0.256408 ┆ 0.146319 ┆ 0.144487 ┆ … ┆ 0.06953  ┆ 0.085817 ┆ 0.098264 ┆ 0.07589  │\n",
       "│ 844      ┆ 0.201087 ┆ 0.143179 ┆ 0.16632  ┆ … ┆ 0.070511 ┆ 0.085437 ┆ 0.09678  ┆ 0.078004 │\n",
       "│ …        ┆ …        ┆ …        ┆ …        ┆ … ┆ …        ┆ …        ┆ …        ┆ …        │\n",
       "│ 1003     ┆ 0.76124  ┆ 0.186156 ┆ 0.868758 ┆ … ┆ 0.076884 ┆ 0.101394 ┆ 0.141376 ┆ 0.08195  │\n",
       "│ 1004     ┆ 0.857234 ┆ 0.184682 ┆ 0.27787  ┆ … ┆ 0.07595  ┆ 0.103158 ┆ 0.159747 ┆ 0.082998 │\n",
       "│ 1005     ┆ 0.782135 ┆ 0.164116 ┆ 0.351139 ┆ … ┆ 0.077257 ┆ 0.107566 ┆ 0.14758  ┆ 0.085454 │\n",
       "│ 1006     ┆ 0.649139 ┆ 0.155732 ┆ 0.353077 ┆ … ┆ 0.077999 ┆ 0.111247 ┆ 0.168184 ┆ 0.085715 │\n",
       "│ 1007     ┆ 0.480786 ┆ 0.154954 ┆ 0.316957 ┆ … ┆ 0.077433 ┆ 0.106205 ┆ 0.172368 ┆ 0.08104  │\n",
       "└──────────┴──────────┴──────────┴──────────┴───┴──────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_wide = predictions_wide.select(pl.col('idx_hour'), pl.exclude('idx_hour'))\n",
    "predictions_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_half_submission_df(input_df: pl.DataFrame, weeks: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a submission CSV file from a Polars DataFrame of thp_vol.\n",
    "    \"\"\"\n",
    "    if weeks == '5w-6w':\n",
    "        range = [840, 1007]\n",
    "    elif weeks == '10w-11w':\n",
    "        range = [1680, 1847]\n",
    "\n",
    "    # Choose rows with first column 'idx_hour' having the values 671-840.\n",
    "    input_df = input_df.filter(pl.col('idx_hour') >= range[0], pl.col('idx_hour') <= range[1])\n",
    "\n",
    "    # Some checks on the input_df\n",
    "    assert input_df.shape == (168, 2881), f\"Expected shape (168, 2881), got {input_df.shape}\"\n",
    "    assert input_df.select(pl.any_horizontal(pl.all().is_null().any())).item() == False, \"Submission dataframe contains null values\"\n",
    "    assert input_df['idx_hour'].head(1)[0] <= range[0] and input_df['idx_hour'].tail(1)[0] >= range[1], \"Submission dataframe does seemingly not contain the correct idx_hour values\"\n",
    "\n",
    "    # Stack the dataframe with f'traffic_DLThpVol_test_5w-6w_{hour}_{beam_id}' as index\n",
    "    # where it cycles through the values 671-840 for hour and then the beam_ids, which are colnames of input_df\n",
    "    # return input_df.unpivot(index='idx_hour')\n",
    "    return input_df.unpivot(index='idx_hour', variable_name='beam_id').with_columns(\n",
    "        pl.concat_str([pl.lit('traffic_DLThpVol_test'), pl.lit(weeks), pl.col('idx_hour') - range[0], pl.col('beam_id')], separator='_').alias('ID')\n",
    "    ).select(['ID', 'value']).rename({'value': 'Target'})\n",
    "\n",
    "\n",
    "def create_submission_csv(input_df: pl.DataFrame, output_filename='traffic_forecast.csv', archiving_dir='submission-csvs-archive') -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a submission CSV file from data in input format that's been extended to cover weeks 5-6 and 10-11.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create half submission dataframes\n",
    "    half_submission_5w_6w = create_half_submission_df(input_df, '5w-6w')\n",
    "    half_submission_10w_11w = create_half_submission_df(input_df, '10w-11w')\n",
    "\n",
    "    # Concatenate the two half submission dataframes\n",
    "    submission_df = pl.concat([half_submission_5w_6w, half_submission_10w_11w], how='vertical')\n",
    "\n",
    "    # Save the submission dataframe to a CSV file for submission, and to wandb\n",
    "    submission_df.write_csv(output_filename)\n",
    "    # wandb.save(output_filename)\n",
    "\n",
    "    # Save the submission dataframe to a CSV file for archiving\n",
    "    if archiving_dir:\n",
    "        archiving_dir = Path(archiving_dir)\n",
    "        archiving_dir.mkdir(parents=True, exist_ok=True)\n",
    "        submission_df.write_csv(archiving_dir / f'{'FINAL'}_{output_filename}')\n",
    "\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEBUG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_config['create_submission_csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    predictions_wide = predictions_wide.with_columns(idx_hour=pl.Series(range(840, 1008)))\n",
    "    # idxs from for 11th week\n",
    "    dummy_w11 = pl.DataFrame({'idx_hour': list(range(1680, 1848))} | {beam_id: [0] * 168 for beam_id in template_df.columns})\n",
    "    ys_final = pl.concat([predictions_wide, dummy_w11], how='vertical_relaxed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_config['create_submission_csv']:\n",
    "    w10_11_df = pl.read_csv('seasonality_final.csv')\n",
    "    \n",
    "    combined_df = pl.concat([predictions_wide, w10_11_df], how='vertical_relaxed')\n",
    "\n",
    "    submission_df = create_submission_csv(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
