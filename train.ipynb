{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "* TODO: add averages for cells and stations, NB inference code will need to be adapted too\n",
    "* TODO: target manipulations/engineering\n",
    "    * rolling autocorrelation\n",
    "* TODO: (vector leaf) multi-output regression\n",
    "* TODO: maybe for week 10-11, we should have radically different approach that does not rely on lag feats, since these will be heavily inpacted by compound errors\n",
    "    * maybe we should train lin reg for trend and xgboost for seasonality only on idx feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roadmap Note\n",
    "Regarding your plan to expand the script to first fit a linear model and then apply XGBoost on the residuals, that's a solid approach known as model stacking or residual modeling. This can be set up as a parameter in W&B for flexibility. When you're ready to implement it, you might consider:\n",
    "\n",
    "* Implementing a Pipeline: Use scikit-learn's Pipeline to chain the linear model and XGBoost.\n",
    "* Parameterization: Add a parameter in your config (e.g., use_linear_model) to toggle this behavior.\n",
    "* Logging: Use W&B to track both models' performances separately and combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from tqdm.notebook import tqdm\n",
    "from wandb.integration.xgboost import WandbCallback\n",
    "import wandb\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from optuna_integration.xgboost import XGBoostPruningCallback\n",
    "from optuna_integration.wandb import WeightsAndBiasesCallback\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import Callable\n",
    "import math\n",
    "from pathlib import Path\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import utils\n",
    "\n",
    "# Manually set the notebook name\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"xgboost_train.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "DEBUG = False\n",
    "# config_file_path = Path('configs') / 'linear_config.yaml'\n",
    "# config_file_path = Path('configs') / 'autoregressive_config.yaml'\n",
    "# config_file_path = Path('configs') / '168hour_shift_config.yaml'\n",
    "config_file_path = Path('configs') / 'SWEEP_autoregressive_config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Extract xgb_hyperparams from config\n",
    "xgb_hyperparams = config.get('xgb_hyperparams', {})\n",
    "\n",
    "# Merge xgb_hyperparams into config\n",
    "config.update(xgb_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Read the CSV files\n",
    "data_dir = Path('input-data')\n",
    "target_dataframes = {\n",
    "    # This is the target variable\n",
    "    'thp_vol': pl.read_csv(data_dir / 'traffic_DLThpVol.csv'),\n",
    "    'prb': pl.read_csv(data_dir / 'traffic_DLPRB.csv'),\n",
    "    'thp_time': pl.read_csv(data_dir / 'traffic_DLThpTime.csv'),\n",
    "    'mr_number': pl.read_csv(data_dir / 'traffic_MR_number.csv')\n",
    "}\n",
    "\n",
    "# Filter target dataframes based on config\n",
    "target_dataframes = {\n",
    "    k: v for k, v in target_dataframes.items() if k in config['target_df_names']}\n",
    "\n",
    "idx_hour_series = target_dataframes['thp_vol']['']\n",
    "\n",
    "# Drop the first column (idx hour) from each dataframe\n",
    "for k in target_dataframes:\n",
    "    target_dataframes[k] = target_dataframes[k].drop('')\n",
    "\n",
    "# Debug mode: shorten dataframes and config lists\n",
    "if DEBUG:\n",
    "    target_dataframes = {k: v.head(200).select(\n",
    "        v.columns[:800]) for k, v in target_dataframes.items()}\n",
    "    config = {k: v[:3] if isinstance(\n",
    "        v, list) else v for k, v in config.items()}\n",
    "\n",
    "# Merge xgb_hyperparams into config\n",
    "config.update(xgb_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:38svctt1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2463d7087db4f54950965265ca4b3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='22.447 MB of 22.447 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_iteration</td><td>▁</td></tr><tr><td>best_score</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇▇██▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆</td></tr><tr><td>validation_0-mae</td><td>▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▆▄▃▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_1-mae</td><td>▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▆▄▃▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_iteration</td><td>115</td></tr><tr><td>best_score</td><td>0.20738</td></tr><tr><td>epoch</td><td>86</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-flower-128</strong> at: <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/38svctt1' target=\"_blank\">https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/38svctt1</a><br/> View project at: <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge' target=\"_blank\">https://wandb.ai/esedx12/traffic-forecasting-challenge</a><br/>Synced 6 W&B file(s), 1 media file(s), 2 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241009_200158-38svctt1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:38svctt1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3cda17817d40d9bcab4b2a6895469c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112631611306116, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/emil/Desktop/Beam-Level Traffic Forecasting Challenge/wandb/run-20241009_200403-eltfqr6u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/eltfqr6u' target=\"_blank\">ancient-spaceship-129</a></strong> to <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge' target=\"_blank\">https://wandb.ai/esedx12/traffic-forecasting-challenge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/eltfqr6u' target=\"_blank\">https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/eltfqr6u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# Initialize W&B\n",
    "run = wandb.init(\n",
    "    project=\"traffic-forecasting-challenge\",\n",
    "    job_type='train',\n",
    "    entity=\"esedx12\",\n",
    "    config=config,\n",
    "    save_code=True,\n",
    "    mode='dryrun')\n",
    "\n",
    "\n",
    "# Save utils.py to W&B\n",
    "utils_path = Path('utils.py')\n",
    "if utils_path.exists():\n",
    "    wandb.save(str(utils_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Feature Engineering\n",
    "\n",
    " The feature engineering steps are handled by utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Use first config.train_percentage of dataframe rows for training, and the rest for validation and testing\n",
    "num_rows = len(target_dataframes['thp_vol'])\n",
    "num_train_rows = round(num_rows * wandb.config.train_percentage)\n",
    "num_val_rows = round(num_rows * wandb.config.val_percentage)\n",
    "\n",
    "# Make feature dataframes\n",
    "feature_dfs = utils.create_all_feature_dfs(\n",
    "    target_dataframes, idx_hour_series, config)\n",
    "\n",
    "train_target_dfs = {k: v.head(num_train_rows)\n",
    "                    for k, v in target_dataframes.items()}\n",
    "train_feature_dfs = {k: v.head(num_train_rows)\n",
    "                     for k, v in feature_dfs.items()}\n",
    "train_idx_hour_series = idx_hour_series.head(num_train_rows)\n",
    "\n",
    "val_target_dfs = {k: v.slice(num_train_rows + 1, num_val_rows)\n",
    "                  for k, v in target_dataframes.items()}\n",
    "val_feature_dfs = {k: v.slice(num_train_rows + 1, num_val_rows)\n",
    "                   for k, v in feature_dfs.items()}\n",
    "val_idx_hour_series = idx_hour_series.slice(num_train_rows + 1, num_val_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create long format dataframes using utility functions\n",
    "long_train_df = utils.create_long_format_df(\n",
    "    train_target_dfs, train_feature_dfs, train_idx_hour_series, wandb.config)\n",
    "long_val_df = utils.create_long_format_df(\n",
    "    val_target_dfs, val_feature_dfs, val_idx_hour_series, wandb.config)\n",
    "\n",
    "target_cols = list(target_dataframes.keys())\n",
    "\n",
    "# Assuming long_train_df and long_val_df are pandas DataFrames\n",
    "X_train = long_train_df.drop(columns=target_cols)\n",
    "y_train = long_train_df[target_cols]\n",
    "\n",
    "X_val = long_val_df.drop(columns=target_cols)\n",
    "y_val = long_val_df[target_cols]\n",
    "\n",
    "wandb.config.update({\n",
    "    'num_train_samples': len(X_train),\n",
    "    'num_val_samples': len(X_val),\n",
    "    'features': X_train.columns.to_list(),\n",
    "    'targets': y_train.columns.to_list()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Train Models\n",
    "*  TODO if indicated for performance reasons, get the max idx_hour with a null and return it so we can shorten the df for multi-step predict\n",
    "* TODO also add target transformations (maybe sklearn can help)\n",
    "* TODO normalize somehow if data is on very different scales for different beams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sk-learn linear model\n",
    "if config['model'] == 'linear':\n",
    "    models = {}\n",
    "    for target in target_cols:\n",
    "        model = sklearn.linear_model.LinearRegression()\n",
    "        model.fit(pd.get_dummies(X_train), y_train[target])\n",
    "        models[target] = model\n",
    "        # wandb log and print some metrics, like mae\n",
    "        y_pred = model.predict(pd.get_dummies(X_val))\n",
    "        mae = sklearn.metrics.mean_absolute_error(y_val[target], y_pred)\n",
    "        wandb.log({f'mae_{target}': mae})\n",
    "        print(f'MAE for {target}: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['beam_id', 'cell_id', 'station_id', 'daily_hours_shifted_0h',\n",
       "       'daily_hours_shifted_6h', 'daily_hours_shifted_12h',\n",
       "       'daily_hours_shifted_18h', 'weekday_shifted_0d', 'weekday_shifted_3d',\n",
       "       'weekday_shifted_6d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting model for thp_vol:\n",
      "[0]\tvalidation_0-mae:0.37370\tvalidation_1-mae:0.37042\n",
      "[25]\tvalidation_0-mae:0.22953\tvalidation_1-mae:0.22956\n",
      "[50]\tvalidation_0-mae:0.20856\tvalidation_1-mae:0.21146\n",
      "[75]\tvalidation_0-mae:0.20339\tvalidation_1-mae:0.20851\n",
      "[100]\tvalidation_0-mae:0.20148\tvalidation_1-mae:0.20763\n",
      "[125]\tvalidation_0-mae:0.19999\tvalidation_1-mae:0.20747\n",
      "\n",
      "Fitting model for mr_number:\n",
      "[0]\tvalidation_0-mae:0.61112\tvalidation_1-mae:0.61702\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mxgb_hyperparams, callbacks\u001b[38;5;241m=\u001b[39m[WandbCallback(log_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFitting model for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m              \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m models[target_name] \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m~/Desktop/Beam-Level Traffic Forecasting Challenge/venv/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Beam-Level Traffic Forecasting Challenge/venv/lib/python3.12/site-packages/xgboost/sklearn.py:1108\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m-> 1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Beam-Level Traffic Forecasting Challenge/venv/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Beam-Level Traffic Forecasting Challenge/venv/lib/python3.12/site-packages/xgboost/training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    185\u001b[0m bst \u001b[38;5;241m=\u001b[39m cb_container\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m~/Desktop/Beam-Level Traffic Forecasting Challenge/venv/lib/python3.12/site-packages/xgboost/callback.py:258\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset name should not contain `-`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 258\u001b[0m score: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n",
      "File \u001b[0;32m~/Desktop/Beam-Level Traffic Forecasting Challenge/venv/lib/python3.12/site-packages/xgboost/core.py:2212\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[0;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m   2209\u001b[0m evnames \u001b[38;5;241m=\u001b[39m c_array(ctypes\u001b[38;5;241m.\u001b[39mc_char_p, [c_str(d[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[1;32m   2210\u001b[0m msg \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[1;32m   2211\u001b[0m _check_call(\n\u001b[0;32m-> 2212\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2220\u001b[0m )\n\u001b[1;32m   2221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2222\u001b[0m res \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# xgboost model\n",
    "def sweep\n",
    "    if config['model'] == 'xgboost':\n",
    "        models = {}\n",
    "        for target_name in y_train.columns:\n",
    "            model = xgb.XGBRegressor(\n",
    "                **xgb_hyperparams, callbacks=[WandbCallback(log_model=True)])\n",
    "            print(f\"\\nFitting model for {target_name}:\")\n",
    "            model.fit(\n",
    "                X_train,\n",
    "                y_train[target_name],\n",
    "                eval_set=[(X_train, y_train[target_name]),\n",
    "                        (X_val, y_val[target_name])],\n",
    "                verbose=25\n",
    "            )\n",
    "            models[target_name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "for target_name, model in models.items():\n",
    "    model_dir = Path('checkpoints') / wandb.run.name\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model_path = model_dir / f'{target_name}.ubj'\n",
    "    pickle.dump(model, open(model_path, 'wb'))\n",
    "    wandb.save(str(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Evaluation and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing target: thp_vol\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- cell_id\n- station_id\nFeature names seen at fit time, yet now missing:\n- cell_id_0_0\n- cell_id_0_1\n- cell_id_0_2\n- cell_id_10_0\n- cell_id_10_1\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m train_preds \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m val_preds \u001b[38;5;241m=\u001b[39m target_model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Compute MAE values\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Beam-Level Traffic Forecasting Challenge/venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:306\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Beam-Level Traffic Forecasting Challenge/venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:285\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    283\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 285\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     coef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coef_\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Beam-Level Traffic Forecasting Challenge/venv/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/Beam-Level Traffic Forecasting Challenge/venv/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- cell_id\n- station_id\nFeature names seen at fit time, yet now missing:\n- cell_id_0_0\n- cell_id_0_1\n- cell_id_0_2\n- cell_id_10_0\n- cell_id_10_1\n- ...\n"
     ]
    }
   ],
   "source": [
    "# # %%\n",
    "# # Iterate through each model in models\n",
    "# for target, target_model in models.items():\n",
    "#     print(f\"Processing target: {target}\")\n",
    "\n",
    "#     # Predict\n",
    "#     train_preds = target_model.predict(X_train)\n",
    "#     val_preds = target_model.predict(X_val)\n",
    "\n",
    "#     # Compute MAE values\n",
    "#     train_mae = mean_absolute_error(y_train[target], train_preds)\n",
    "#     val_mae = mean_absolute_error(y_val[target], val_preds)\n",
    "\n",
    "#     # Log the best score to wandb\n",
    "#     # XGBoost does not have best_iteration attribute in scikit-learn API\n",
    "#     evals_result = target_model.evals_result()\n",
    "#     best_iteration = len(evals_result['validation_0']['mae'])  # Last iteration\n",
    "#     best_val_mae = evals_result['validation_1']['mae'][-1]\n",
    "#     best_train_mae = evals_result['validation_0']['mae'][-1]\n",
    "\n",
    "#     wandb.log({\n",
    "#         f'{target}_best_val_mae': best_val_mae,\n",
    "#         f'{target}_best_round': best_iteration,\n",
    "#         f'{target}_best_train_mae': best_train_mae\n",
    "#     })\n",
    "\n",
    "#     # Convert evaluation results to a DataFrame\n",
    "#     eval_df = pl.DataFrame({\n",
    "#         'Round': list(range(1, len(evals_result['validation_0']['mae']) + 1)),\n",
    "#         'Train MAE': evals_result['validation_0']['mae'],\n",
    "#         'Val MAE': evals_result['validation_1']['mae']\n",
    "#     })\n",
    "\n",
    "#     # Log eval_df to wandb\n",
    "#     wandb.log({f'{target}_eval_df': wandb.Table(data=eval_df.to_pandas())})\n",
    "\n",
    "#     # Plot the results using Plotly\n",
    "#     fig = px.line(\n",
    "#         eval_df.to_pandas(),\n",
    "#         x='Round',\n",
    "#         y=['Train MAE', 'Val MAE'],\n",
    "#         labels={'value': 'Mean Absolute Error'},\n",
    "#         title=f'Training and Validation MAE over Boosting Rounds for {target}'\n",
    "#     )\n",
    "\n",
    "#     fig.update_layout(\n",
    "#         legend=dict(\n",
    "#             title='Dataset',\n",
    "#             itemsizing='constant'\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     # Log the plot to wandb\n",
    "#     wandb.log({f\"{target}_MAE_Plot\": fig})\n",
    "\n",
    "#     # Optionally, display the plot\n",
    "#     fig.show()\n",
    "\n",
    "#     print(f\"Best Val MAE for {target}: {best_val_mae}\")\n",
    "#     print(f\"Round: {best_iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if wandb.config.run_shap:\n",
    "    # Create a SHAP explainer for the XGBoost model\n",
    "    # Assuming 'thp_vol' is one of the targets\n",
    "    target_name = 'thp_vol'\n",
    "    explainer = shap.TreeExplainer(models[target_name], X_val)\n",
    "\n",
    "    # Calculate SHAP values for the val set\n",
    "    shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "    # Log SHAP plots to wandb\n",
    "    shap_bar = shap.summary_plot(\n",
    "        shap_values, X_val, plot_type=\"bar\", show=False)\n",
    "    plt.savefig(\"shap_bar.png\")\n",
    "    wandb.log({\"SHAP Bar Plot\": wandb.Image(\"shap_bar.png\")})\n",
    "    plt.clf()\n",
    "\n",
    "    shap_summary = shap.summary_plot(\n",
    "        shap_values, X_val, show=False)\n",
    "    plt.savefig(\"shap_summary.png\")\n",
    "    wandb.log({\"SHAP Summary Plot\": wandb.Image(\"shap_summary.png\")})\n",
    "    plt.clf()\n",
    "\n",
    "    # Optionally, add more SHAP plots as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ddf878b48d4bde9790dbbe1580d8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='72.802 MB of 109.894 MB uploaded\\r'), FloatProgress(value=0.6624796175588117, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_iteration</td><td>▁█</td></tr><tr><td>best_score</td><td>█▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>mr_number_best_round</td><td>▁</td></tr><tr><td>mr_number_best_train_mae</td><td>▁</td></tr><tr><td>mr_number_best_val_mae</td><td>▁</td></tr><tr><td>thp_vol_best_round</td><td>▁</td></tr><tr><td>thp_vol_best_train_mae</td><td>▁</td></tr><tr><td>thp_vol_best_val_mae</td><td>▁</td></tr><tr><td>validation_0-mae</td><td>▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁█▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_1-mae</td><td>▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂█▆▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_iteration</td><td>100</td></tr><tr><td>best_score</td><td>0.23667</td></tr><tr><td>epoch</td><td>109</td></tr><tr><td>mr_number_best_round</td><td>111</td></tr><tr><td>mr_number_best_train_mae</td><td>0.21294</td></tr><tr><td>mr_number_best_val_mae</td><td>0.2368</td></tr><tr><td>thp_vol_best_round</td><td>63</td></tr><tr><td>thp_vol_best_train_mae</td><td>0.23135</td></tr><tr><td>thp_vol_best_val_mae</td><td>0.26496</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vague-vortex-119</strong> at: <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/rkrpnm57' target=\"_blank\">https://wandb.ai/esedx12/traffic-forecasting-challenge/runs/rkrpnm57</a><br/> View project at: <a href='https://wandb.ai/esedx12/traffic-forecasting-challenge' target=\"_blank\">https://wandb.ai/esedx12/traffic-forecasting-challenge</a><br/>Synced 6 W&B file(s), 6 media file(s), 6 artifact file(s) and 4 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241009_192352-rkrpnm57/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
